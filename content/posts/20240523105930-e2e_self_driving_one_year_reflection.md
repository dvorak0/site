+++
title = "E2E Self-Driving One-year Reflection"
date = 2024-05-23T10:59:00+08:00
tags = ["e2e", "PUBLIC", "DM"]
draft = false
+++

(shamefully)因为wayve的新融资，不免的再次想起这个话题。

<!--more-->

翻出来[E2E Self-Driving in the Era of GPT]({{< relref "20230322100018-end_to_end_selfdriving_in_the_era_of_gpt.md" >}})来看，大部分想法是一致的，现在想到的和当时想到的并没有明显矛盾的地方。

不过有一些进一步的想法。

先回忆起试验结果[comma_ai]({{< relref "20230425113719-comma_ai.md" >}})，当前明显的结果是，当前模型的输出是不够好的，两个证据：

1.  carla的结果保持了一个很低的分数，上次自己实验用comma.ai的model在模拟器表现的结果是安全有余，经常卡住
2.  还是要承认，结合其他车企的表现，应该还是要说目前接管率还是不够，但是这个gap在变得更小。
    -   参考[全自动驾驶的里程碑，吗？]({{< relref "20240130180127-全自动驾驶的里程碑_吗.md" >}})
    -   再结合百度在无人的无人驾驶部署，打听目前是1安全员对2台车。不知道是不是真的百度内部得到了一个模型，有机会做到盈利？
        不过在这里打听里，也感觉百度的大公司病太严重了，体现在员工的养老状态加上leader的对向上汇报的重视。

所以在今天，


## 新的熵增是什么 {#新的熵增是什么}


### larger model {#larger-model}

今天看起来很明显，但是去年这个时候竟然完全没有提，甚至没有去看comma ai的model size。

今天看了下，模型是49.1M。这个size如果不是隐瞒了严重的问题的话，就一定是一个大的潜在机会。


### 视频生成的进展 {#视频生成的进展}

这里要提到，自上次的乐观之后，新了解到的一个概念，事关模仿学习的根基。

这个问题有点难以刻画，好像也没有形成普遍的概念。

这个问题是在描述，如果这个模型模仿的数据都是高水平数据（人类水平），他是否能学会应对事故（因为救车操作，或者说避免车道画龙操作，在数据里很少）。

更正式一点说，有点像模仿学习的数据分布，要比部署时候在control loop里面看到的数据分布，更加“窄”。

我自己意识到这个问题是在[Imitation Learning](https://geohot.github.io/blog/jekyll/update/2023/11/18/imitation-learning.html)。幸运的是，geohot同时给出了一个提示。

虽然他没有说清楚是什么解法，我结合当时的时间以及<https://github.com/commaai/commavq>。

我现在认为这个解法，是用视频生成去做arugment！用conditioned video generation去仿真。
比如把一个车道线居中操作，仿真成画龙（再控制回居中）。这样让模型去扩大适应的分布。


### 更普遍地看中数据质量。 {#更普遍地看中数据质量}

更加相信：数据集的high-quality是很重要的，比quantity要更加重要。

手工做去数据的去重，权重调整，是现在LLM训练的标配。


## 新的问题是什么 {#新的问题是什么}

结合以上两点吧。有没有机会做到：

-   carla的碰撞率降低一个数量级到1%，用各种方法。
-   如果可以，那么model size和collision rate的plot，是不是具备scaling law？
-   如何“精心地”准备数据。现在的两个做法：
    1.  用youtube driving。行车记录仪类型的。这里需要跑定位，然后用视频+轨迹做监督。
    2.  自己录。自动驾驶类的，这里不跑定位，用视频+控制信号做监督。
