+++
title = "人类CoT典范，张祥雨的Line of Research"
date = 2025-06-05T17:01:00+08:00
tags = ["PUBLIC"]
draft = false
+++

这个访谈似乎在张小珺自己的一系列访谈里，显得比较突出。

我自己是在听到一半的时候，决定要记录一下。

主要是被张祥雨清晰的表达震撼，明显感觉他的表达的context很长，能维持一个很长的逻辑链，有的逻辑分支走完了还能回溯。

说回内容。

可以概括为，一个发自内心对智能有追求的人，是如何对AI发展中的节点进行审美的。

<!--more-->

1.  研究线的主旋律是如何Scale
2.  首先Data scale，imagenet终结了数据问题，之后的很长一段时间不需要考虑Data的规模问题。所以主要考虑模型架构。
3.  针对模型宽度的scale 做了MSRA init。（其实没懂这个逻辑）
4.  针对模型深度的scale做了resnet，模型从几M，做到几十M。
5.  继续加深有没有用呢，对于大模型没有用了，只要大体设计对了，性能差别不大。
6.  在旷视做落地部署，小模型有商业价值。并且发现架构设计对小模型更有用，所以做NAS。
7.  发现GPT3太牛了，觉得自己搞了这么多年，只不过是在做representation，NLP都做到推理能力了。离“智能”更近。
8.  为什么NLP有scale，CV没有scale。
9.  语言的学习形式更好，用完形填空的方法，是在学习联合概率。CV的label是在学习条件概率。
10. 联合概率不需要label，数据更多。
11. CV能学习联合概率吗，换句话说，CV可以做生成任务吗？
12. 生成任务怎么做，一个小高潮是Masked Image Modeling。但是感觉还是不对劲，毕竟依旧是人类知识的注入。
    1.  张祥雨认为是在学习遮挡不变性而已：Understanding Masked Image Modeling via Learning Occlusion Invariant Feature
13. 还是要找到做图片生成的方法。
14. 时间线拉回一点，ViT出现了，图片可以进Transformer了，把Image Token和Language Token简单对齐一下就可以做多模态了。
15. 创业做公司，Step-1做出来了，图文混排进Transformer，decoder同时做图生成和文生成。图生成这一阶段是外挂diffusion。
16. 结果，理解力很强，比如描述图片的能力。OCR顺手就被模型解决了。
17. 但是生成很差，基本不可控。
18. 更可怕的是，出发点是用图片生成这个形式（学习联合概率）来学习智能，但是发现把diffusion分支去掉，理解能力依旧很强。这不是说明图片生成并没有帮助来学习智能吗。
19. 猜想1，数据不好，互联网上的图文对不够高质量。那么交替的做，先做一个模型，这个模型理解力很强，那么用这个模型做caption合成数据，再训练下一轮模型。
20. 没有成功。
21. 猜想2，模型不够大，没训好。做了一个200B激活的网络。
22. 有了一个核心观察。模型越大，文科能力越强，理科能力越差。
23. 怎么解释。矛头直指Next Token Prediction这个范式，或者说压缩产生智能这个范式。
24. 举个例子：如果语料中，有两类数学题，一类是跳步的，一类是不跳步的。模型在NTP这个范式下，应该学到什么：一半概率猜测/记忆，一半概率推理。
25. 所以就能解释了，小模型记忆能力不行，所以只有靠推理，但是大模型记忆能力好，反而有了更高的压缩率，但是现在高压缩率是有害的。
26. （插一句，我觉得也经常发现，记忆力好的人和推理能力好的人是两类人，这两个能力似乎就是互相排斥的）
27. NTP的问题能解决吗。
28. 线索回到NLP模型，o1带来了什么启示。
29. CoT是有用的，从复杂度的视角，不能预期任何难度的问题都在一个Token下解决。
30. 所以o1用CoT扩展了复杂度，从而应对不同难度的问题。
31. 具体的方法就是rule-based RL，直接在编程和数学的领域设置reward，RL跑起来，性能提升了。
32. 这么简单的想法，之前怎么没做成。
33. 可能是OpenAI发现了rule-based RL应该用什么pattern的CoT，更像是在解决CoT的CoT，meta CoT问题。
34. 他是怎么找到recheck/wait/alternatively这些关键词的。
35. 猜测是观察数据，StackOverFlow很多回答，带有这些关键词。
36. 总之，用独特的pattern去诱导CoT，做work了。
37. 是RL的胜利吗。
    感觉此RL已经不是彼RL了。经典的RL要解决的问题，主要是reward稀疏的问题，比如随机打游戏，通关的概率在冷启动的时候是很小的。
    但是在NLP这个问题里面，pretrain的模型的搜索空间不是冷启动的。关键的critical decision只有那么几个。任何算法都可以work，不重要。
38. CoT的pattern算不算人类知识的注入呢，如果完全靠学习能不能学到。现在来看，base model增强之后，也是可以学到的，但是效率不高。
39. 现在可以继续回到图片了，图片的CoT有吗。现在来看，还没有。但是已经能感觉到图片推理是核心问题了，比如看图走迷宫这种。也呼应了最近的图片推理方法的热点。
40. 一些尝试，合成数据，自己做图片走迷宫数据。结果来看，泛化性不行。
41. OpenAI又来指路了，新模型o4的图片推理能力展示出来很好的泛化性。他找到的pattern是crop/resize。可能是新的答案吧。
42. 图片的o1时刻可能会在一年内到来。
43. 一些问题：Long Context重要吗。不重要。
    1.  一个想法是，人类没有那么长的短期记忆。
    2.  另外，Long Context可以用很多方法去实现，比如用Function Calling，比如用两个LLM，一个做plan，一个做execution，执行的LLM可以并行多实例。
        对于一个给定的逻辑树，遍历所需要的context就从N，变成Log(N)。
    3.  两个LLM的是agent系统，不是端到端模型。这种说法对吗，当然不对，有了RL，可以把multi-LLM一起训练，也用rule-based reward，强迫模型自己找到合作方式，在有限的context length下。
44. AGI的关键方法都找到了吗？感觉下一层还需要解决一个模型自驱动的问题，毕竟人类不是做每件事情都有KPI的。
