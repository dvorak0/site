<!doctype html><html lang=zh-cn><head><meta charset=UTF-8><meta name=description content="self-reflections of Zhenfei Yang"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>E2E Self-Driving in the Era of GPT</title>
<link rel=stylesheet href=../../css/style.css></head><body><header><script defer src=https://worker.yangzhenfei.com/a.js></script><script defer>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JHXS14NDHV")</script>========================<br>== <a href=https://www.yangzhenfei.com/>Seeking Complexity</a> ==<br>========================<div style=float:right></div><br><p><nav><a href=../../><b>Start</b></a>.
<a href=../../posts/><b>Posts</b></a>.
<a href=../../tags/><b>Tags</b></a>.
<a href=../../about/><b>About</b></a>.</nav></p></header><main><article><h1>E2E Self-Driving in the Era of GPT</h1><b><time>2023-03-22 10:00:00</time></b>
<a href=../../tags/e2e>e2e</a>
<a href=../../tags/public>PUBLIC</a>
<a href=../../tags/dm>DM</a><div><p>大模型可以解决什么问题。</p><h2 id=200公里>200公里？</h2><p>抛开“L4做不成”的观点，讨论“L4哪里做不成”的事实。</p><p>Mobileye认为Robotaxi的质变点在于MTBF=10^7小时。那当前各家做到了什么水平呢：</p><p>小道消息：</p><ul><li>Pony的安全员：一两周一次</li><li>华为阿维塔，“200公里勉勉强强”</li><li>元戎 “比200公里低”</li></ul><p>各家投入了200至1000名工程师，去克服这个问题，各个模块都尽可能地follow tesla，目前达到的水平就是如此。</p><p>是不是说明这条路很难scale up？无论是测试量，还是实际的MTBF，都需要考虑：证明MTBF是10^7，一定需要比10^7高一个数量级的测试量。</p><p>有没有绝对无法解决的问题？<a href>why_L4_is_hard</a></p><h2 id=comma-ai>comma ai</h2><p>这个23个人的公司做到了什么。</p><figure><img src=../../ox-hugo/2023-03-29_11-17-17_screenshot_hu_b25bc78c39900525.webp height=743 width=1280></figure><figure><img src=../../ox-hugo/2023-03-29_11-20-30_screenshot_hu_9bec5361b6eb06b0.webp height=1465 width=1280><figcaption><span class=figure-number>Figure 1: </span>from consumer report</figcaption></figure><p>GeoHot是搞怪的还是认真做的。</p><figure><img src=../../ox-hugo/2023-04-10_15-38-42_screenshot_hu_30acbbc0dced15ba.webp height=441 width=1280></figure><h2 id=具体来说是什么路径>具体来说是什么路径</h2><p>(<strong>pretrain</strong> -> prediction/planning) + control/adapter</p><p>我们对prediction/planning + control，不陌生。</p><p>新的熵减来自，pre-trained large model。关键在于如何做到，以及做到之后有多大帮助（寻找scaling law）。</p><p>找pre-trained large model，约等于找数据在无标注下能利用的内在一致性是什么，比如：</p><ul><li>语言是不是流畅是语言的内在一致性</li><li>同样的物体，在不同视角下看到的外表，在某种变换下是等价的</li><li>图片有内容，而不是乱码，通过遮挡一部分，我们也能知道里面画的是什么。</li></ul><p>那么自动驾驶的一致性是什么。</p><h2 id=一致性从哪里来>一致性从哪里来</h2><p>自动驾驶的一致性就是轨迹，特别的，是自己的车的轨迹。</p><p>这个信号相当于自动驾驶的world model，在预测自己的下一步的时候，要做很多内在的任务（哪里可以开，不能撞到什么，要不要减速）。</p><p>按analysis by synthesis的思路：如果模型可以对下一步去哪预测的很好，我们可以认为他 <strong>理解</strong> 了这个世界。</p><p>如何获取大量轨迹：可以用youtube上的行车记录仪数据。</p><figure><img src=../../ox-hugo/2023-04-10_15-45-06_screenshot_hu_182197a3d7f02bdf.webp height=536 width=1280></figure><h2 id=别人想到这个想法之后-做过哪些工作>别人想到这个想法之后，做过哪些工作</h2><p>我们看看现有的工作是怎么解决轨迹来源：</p><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>PPGeo<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></td><td>Shanghai AI lab</td><td>用NN的Posenet出轨迹</td><td>精度不高，不能直接用，要再加一次投影误差</td></tr><tr><td>ACO<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></td><td>zhou bolei</td><td>用action做对比学习</td><td>粒度很粗</td></tr><tr><td>UniAD<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></td><td>Shanghai AI lab</td><td>模块化的网络结果，但是只用轨迹做监督</td><td>数据很少</td></tr><tr><td>comma.ai</td><td></td><td>EKF(orb-slam, GPS)</td><td>做的很早(提一嘴，live coding，11个小时搞定)</td></tr></tbody></table><p>这么看，comma ai才是那个做 <strong>难且正确</strong> 的事的人。</p><p>所以这像是两个圈子被隔绝开，能准备数据的人不会大规模训练，会大规模训练的人无法做轨迹的自动化标注（也就是建图）。</p><h2 id=是不是很昂贵>是不是很昂贵</h2><p>大模型是少数人的特权吗。看看常见的工作需要多少GPU时。</p><table><thead><tr><th></th><th>数据规模</th><th>GPU需求</th><th>备注</th></tr></thead><tbody><tr><td>PPGeo<sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></td><td>48小时视频</td><td>A100 x 64</td><td>nuScenes中今年top1</td></tr><tr><td>ACO<sup id=fnref1:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></td><td></td><td>8 GPU</td><td></td></tr><tr><td>Seg-everything<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></td><td>11M 图片</td><td>256 A100 GPUS for 68 hours</td><td>网红</td></tr><tr><td>VideoMAE v2<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup></td><td></td><td>240小时 64 A100</td><td>最大视觉预训练</td></tr></tbody></table><p>GPU价格计算：</p><p><figure><img src=../../ox-hugo/2023-04-10_16-07-09_screenshot.png alt></figure>100块一年需要1.5 * 24 * 365 = 130w美元 = 940w人民币。</p><p>还是很贵的。明显的节省方向是：</p><ul><li>实际只有last run需要最大资源</li><li>不一定train-from-scrach</li><li>不一定用A100 80G</li></ul><p>还是挺贵的，对实验要求很高。</p><h2 id=这样做距离l4差多少>这样做距离L4差多少</h2><p>UniAD汇报的结果：</p><figure><img src=../../ox-hugo/2023-04-10_16-13-45_screenshot_hu_283d39dc2d5fd565.webp height=659 width=1280></figure><p>其中关注MR(missing rate预测轨迹和实际轨迹完全不一致）和minADE（轨迹的距离误差）。</p><p>粗略来看，15%的MR和0.7的minADE都不算好。</p><p>甚至作者自己短短的预览结果里都有明显的过度躲避</p><figure><img src=../../ox-hugo/2023-04-10_16-15-47_screenshot_hu_6cb84971a265978a.webp height=303 width=1280></figure><p>是不是对指标理解存在偏差？从youtube上众多comma three的结果来看，其表现都要比这更自然。</p><h2 id=a-key>a key</h2><p><a href>MoE_as_Redundancy</a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Learning to Drive by Watching YouTube videos: Action-Conditioned Contrastive Policy Pretraining&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Planning-oriented Autonomous Driving&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Segment Anything&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article></main><script src=https://utteranc.es/client.js repo=dvorak0/site issue-term=pathname theme=github-light crossorigin=anonymous async></script><script async src=https://www.yangzhenfei.com/js/mathjax-config.js></script><script type=text/javascript async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-chtml.min.js></script><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=../../posts/20250516101712-building_music_theory_from_the_scratch/>Music Theory: Building from the Scratch</a></li><li><a href=../../posts/20250508121432-%E6%A8%A1%E4%BB%BF%E5%8F%AF%E4%BB%A5%E4%BA%A7%E7%94%9F%E6%99%BA%E8%83%BD%E5%90%97/>E2E Self-Driving: 模仿可以产生智能吗？</a></li><li><a href=../../posts/20250506141744-%E6%9D%8E%E5%85%89%E8%80%80%E8%A7%82%E5%A4%A9%E4%B8%8B/>《李光耀观天下》</a></li><li><a href=../../posts/20250506140144-%E8%A7%A3%E6%9E%84%E7%8E%B0%E4%BB%A3%E5%8C%96_%E6%B8%A9%E9%93%81%E5%86%9B%E6%BC%94%E8%AE%B2%E5%BD%95/>《解构现代化：温铁军演讲录》</a></li><li><a href=../../posts/20250207171318-%E5%A4%96%E6%98%9F%E4%BA%BA/>外星人</a></li></ul></div></div></aside><footer><p>&copy; 2025 <a href=https://www.yangzhenfei.com/><b>Seeking Complexity</b></a>.
<a href=https://github.com/dvorak0><b>Github</b></a>.
<a href=https://twitter.com/dvorak0><b>Twitter</b></a>.</p></footer></body></html>