<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>make the world a better place</title><link rel=stylesheet href=../../css/style.css></head><body><header><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?41e2e31fcfdb815d942715d44866f9fc",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script>========================<br>== <a href=https://www.yangzhenfei.com>Seeking Complexity</a> ==<br>========================<div style=float:right></div><br><p><nav><a href=../../><b>Start</b></a>.
<a href=../../posts/><b>Posts</b></a>.
<a href=../../about/><b>About</b></a>.</nav></p><script src=https://www.yangzhenfei.com/js/mathjax-config.js></script>
<script type=text/javascript async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-chtml.min.js></script></header><main><article><h1>make the world a better place</h1><b><time>2023-01-09 10:43:00</time></b>
<a href=../../tags/public>PUBLIC</a><div><figure><img src=../../ox-hugo/2023-01-09_10-44-41_screenshot_hu93acec1b7e4499b726fc95761cff38b0_187819_720x415_resize_q75_h2_box_3.webp></figure><p>哈哈，本来挺好的一个愿景，现在变味了。</p><p>平常难免屈从于各种各样的短期目标，过程中也感觉到，做的东西是挺好的，但是又不够好。</p><p>还是希望有一个更大更香的胡萝卜在前面。</p><p>现在大概有三类大饼，让我真心向往。</p><h2 id=自动驾驶-1-10价格的滴滴>自动驾驶：1/10价格的滴滴</h2><p>2022年大家已经比较趋同地放弃robotaxi的商业可能性了，勇敢地拥抱了竞争激烈的辅助驾驶市场：
好的方面是汽车销量和自动驾驶的渗透率都在超预期上升，坏的方面是同质化严重导致价值集中聚集在品牌方。</p><p>我自己并不是从业者，从外人的视角来看，一定存在MTBF到了某个值，使得robotaxi（+ 1vN 遥控员）的成本低于滴滴（+ 1v1 驾驶员）一个数量级。</p><p>有几个前置条件：</p><ul><li>消费者（包括车厂）是从众的，也就是他看到别人（在有限的时间）是安全的，他也会认为自己是安全的。
这个"看到"要多久，mobileye给出的答案是 \(10^7\) 小时：</li></ul><figure><img src=../../ox-hugo/2023-01-09_11-48-05_screenshot_hua14587e69a1f49340843d3e6ed36f979_39580_1280x194_resize_q75_h2_box_3.webp></figure><ul><li>现有的范式是足够达到MTBF的，这里用到两个曲线：<ul><li><p>模型capacity：算法precision-recall vs data size，对应tesla强调的<a href>software 2.0</a>
经过tesla的教育，大家都理解了。</p></li><li><p>冗余度（逆融合）是什么，也可以说是融合更早发生和更晚发生分别有什么优缺点，对应mobileye强调的<a href>True Redundency</a></p><p>更早地融合，系统更黑盒，更容易有更好的成绩，有利于拟合。
更晚地融合，更平行，更独立，有利于测试。</p><p>有点像一个系统设计，你是从起点开始设计，还是从终点开始设计：</p><p>如果你从起点开始设计，最关心的是如何是现在的系统更好，那么应该要更好的成绩，要更早地融合。</p><p>如果你从终点开始设计，要先关心如何达到给定的测试量：最晚的融合对应的测试量是不同的车，再回一步是，同样的车，两套系统（pure vision & pure lidar)，也可以继续回。</p><p>看起来依旧是可以追求的，路子还没有锁死。</p></li></ul></li></ul><h2 id=家用机器人-自然语言的全任务交互>家用机器人：自然语言的全任务交互</h2><p>不得不承认自己对自己之前的想法动摇了，本来觉得抓取的技术都难以跨越，经过ChatGPT的洗礼，AGI的实现又一次被提起。</p><p>ChatGPT人格化的回答，给了我一种新的对AGI的理解。如果一个并不具有智慧的agent，实际上，可以接受语言形式的指令，做到难度依次提升的任务：</p><ol><li>人格化的对话</li><li>写一些文字给我</li><li>操作所有的软件</li><li>做一杯咖啡<a href=https://ai.googleblog.com/2022/12/rt-1-robotics-transformer-for-real.html>RT-1</a></li></ol><figure><img src=../../ox-hugo/2023-01-09_11-26-00_screenshot_hu9222452aba31f32f1fbbe22eef090f98_311652_1280x716_resize_q75_h2_box_3.webp></figure><p>是不是已经是一个革命性地AGI实现了。</p><p>期待机器学习这些莽夫继续去革命机器人领域。</p><h2 id=元宇宙-脱实向虚>元宇宙：脱实向虚</h2><p>我自己是认为这个是我最期待的，我完全不介意我自己的意识脱离自己的肉体，不过这种取向一定是有很大争议的。</p><p>人类的终点在哪里呢，盲目猜测现在的生产力，已经足够每个人每周工作一天，过上老友记里面的生活了。</p><p>现在的额外工作，很多是为了“新型”的享乐：我要穿更花哨的衣服，我要吃更稀有的动物，我要去没去过的地方，我要更大的房子更流线型的汽车。</p><p>这样下来，我们是不是更快乐了？</p><figure><img src=../../ox-hugo/2023-01-09_11-34-09_screenshot_hu53e0098b52fed2ca18e9fb35c12bde95_4518317_1920x2555_resize_q75_h2_box_3.webp></figure><p>从这个角度里，元宇宙似乎像是一种残酷的实验，强化更抽象的概念（更强的人和人的连接），弱化更具体的概念（更弱的物质享受）。</p><p>扯的有点远了。</p><p>现在元宇宙太虚了，太多技术还不成熟，太多应用都流行不起来。</p><p>上一次印象深刻的概念还是用video seethrough去实现AR，非常接地气的想法：基本上共享了手机的发展路径（更高分辨率的相机，更强的显示芯片，更HDR的屏幕）。
看好。</p><h2 id=总结>总结</h2><p>都是不太“靠谱”的想法，但是还是希望有生之年能看到，不然现在的这些进展，实在很难相信如何make the world a better place。</p></div></article></main><script src=https://utteranc.es/client.js repo=dvorak0/site issue-term=pathname theme=github-light crossorigin=anonymous async></script><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=../../posts/20230510165215-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86geohot/>重新认识geohot</a></li><li><a href=../../posts/20230417104236-intelligential_honest/>intelligential honest</a></li><li><a href=../../posts/20230315161517-incremental_run/>Universal Caching, lessons learned from NX</a></li><li><a href=../../posts/20230109104349-make_the_world_a_better_place/>make the world a better place</a></li><li><a href=../../posts/20221205145412-low_information_heuristics/>low_information_heuristics</a></li></ul></div></div></aside><footer><p>&copy; 2023 <a href=https://www.yangzhenfei.com><b>Seeking Complexity</b></a>.</p></footer></body></html>