<!doctype html><html lang=zh-cn><head><meta charset=UTF-8><meta name=description content="self-reflections of Zhenfei Yang"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>E2E Self-Driving: 模仿可以产生智能吗？</title>
<link rel=stylesheet href=../../css/style.css></head><body><header><script defer src=https://worker.yangzhenfei.com/a.js></script><script defer>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JHXS14NDHV")</script>========================<br>== <a href=https://www.yangzhenfei.com/>Seeking Complexity</a> ==<br>========================<div style=float:right></div><br><p><nav><a href=../../><b>Start</b></a>.
<a href=../../posts/><b>Posts</b></a>.
<a href=../../tags/><b>Tags</b></a>.
<a href=../../about/><b>About</b></a>.</nav></p></header><main><article><h1>E2E Self-Driving: 模仿可以产生智能吗？</h1><b><time>2025-05-08 12:14:00</time></b>
<a href=../../tags/e2e>e2e</a>
<a href=../../tags/public>PUBLIC</a><div><p>一条漂亮干净的路径，通往机器人的高可靠性终点。</p><p>从能吃下数据的尺度来排序：</p><ol><li><p>Internet-Scale Data</p><p>无监督的训练掌握 <strong>常识</strong></p><p>DINOv2变成de faco image encoder</p><p>自动驾驶中用视频生成做模拟器，可以不只利用驾驶数据，更多普通数据可以包含更多自然的知识</p></li><li><p>人类示教数据</p><p>模仿学习的数据介绍 <strong>领域知识</strong></p><p>Behavior Cloning + Video Generation-based Augmentation</p><p>更fancy的说法是world model，或者lecun的JEPA</p></li><li><p>打分数据</p><p>在两个采样中，A比B更好，表达 <strong>偏好</strong></p><p>用交替训练的方法，同时训练Reward Model，以及用这个Reward Model支持RL</p><p>有一个机器臂的工作用了这个方法，<a href=https://hil-serl.github.io/>HiL-serl</a></p></li></ol><p>看起来能统一地解决自动驾驶和机械臂的问题。</p><p>今天主要讨论模仿学习如何结合视频生成解决分布漂移的死结。</p><h2 id=前情提要>前情提要</h2><h3 id=23-dot-03-dot-22--e2e-self-driving-in-the-era-of-gpt--20230322100018-end-to-end-selfdriving-in-the-era-of-gpt-dot-md>(23.03.22) <a href=../../posts/20230322100018-end_to_end_selfdriving_in_the_era_of_gpt/>E2E Self-Driving in the Era of GPT</a></h3><p>起点是对comma ai的分析。</p><ul><li>为什么<a href=../../posts/20230510165215-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86geohot/>geohot</a>可以对他自己的方案（一个非常粗放的端到端方案）如此有信心？</li><li>距离<a href=../../posts/20230109104349-make_the_world_a_better_place/>make the world a better place</a>中提到的终极目标MTBF=10^7还差多远？</li><li>预训练模型（所谓的large model）对自动驾驶的帮助有多大，自动驾驶的Scaling Law存在吗？</li><li>如果存在，怎么训练，要花多少钱？</li></ul><h3 id=24-dot-05-dot-23--e2e-self-driving-one-year-reflection--20240523105930-e2e-self-driving-one-year-reflection-dot-md>(24.05.23) <a href=../../posts/20240523105930-e2e_self_driving_one_year_reflection/>E2E Self-Driving One-year Reflection</a></h3><p>Wayve融资启发的一些想法。</p><ul><li>端到端方法连在模拟器Carla的结果都普遍很差</li><li>Large Model对自动驾驶的帮助依旧不是共识</li><li>用视频生成，对模仿学习的数据进行Augment的路径似乎开始清晰<ul><li>视频生成牛了</li><li><a href=https://geohot.github.io/blog/jekyll/update/2023/11/18/imitation-learning.html>Imitation Learning</a>的问题（Distribution Drift）变成最明显的障碍</li></ul></li></ul><h2 id=更多的公开讨论>更多的公开讨论</h2><h3 id=问题一-自动驾驶的scaling-law存在吗>问题一：自动驾驶的scaling law存在吗</h3><p>先说结论，Open-Loop存在，Close-Loop不存在。</p><p>或者说：模仿学习存在，但是模仿学习无法解决闭环控制。</p><h4 id=24-dot-12-dot-03--preliminary-investigation-into-data-scaling-laws-for-imitation-learning-based-end-to-end-autonomous-driving-https-arxiv-dot-org-abs-2412-dot-02689>(24.12.03) Preliminary Investigation into Data Scaling Laws for Imitation Learning-Based End-to-End Autonomous Driving <a href=https://arxiv.org/abs/2412.02689>https://arxiv.org/abs/2412.02689</a></h4><ul><li>理想汽车团队</li><li>数据量：4M sample，30k hours</li><li>Close Loop，从2M samples开始平坦</li></ul><figure><img src=../../ox-hugo/2025-05-08_14-56-27_screenshot_hu_feb5fe9ff3e537a0.webp height=399 width=1280></figure><h4 id=25-dot-04-dot-06--data-scaling-laws-for-end-to-end-autonomous-driving-https-arxiv-dot-org-abs-2504-dot-04338>(25.04.06) Data Scaling Laws for End-to-End Autonomous Driving <a href=https://arxiv.org/abs/2504.04338>https://arxiv.org/abs/2504.04338</a></h4><ul><li><p>Nvidia团队</p></li><li><p>数据量：400k km，8k hours</p></li><li><p>Close Loop，从256 hours开始平坦</p></li><li><p>一通操作之后，实机部署，MTBF=24.41km</p><figure><img src=../../ox-hugo/2025-05-08_14-56-50_screenshot_hu_565a981a3576ec80.webp height=959 width=1280></figure></li></ul><h3 id=问题二-视频生成怎么帮助解决distribution-drift>问题二：视频生成怎么帮助解决Distribution Drift</h3><h4 id=2010-dot-12-dot-02--a-reduction-of-imitation-learning-and-structured-prediction-to-no-regret-online-learning-https-arxiv-dot-org-abs-1011-dot-0686>(2010.12.02) A reduction of imitation learning and structured prediction to no-regret online learning <a href=https://arxiv.org/abs/1011.0686>https://arxiv.org/abs/1011.0686</a></h4><ul><li>先驱工作DAgger</li><li>先部署，等车出问题了，人接管，再来把人接管的这段数据。</li></ul><h4 id=24-dot-09-dot-25--mitigating-covariate-shift-in-imitation-learning-for-autonomous-vehicles-using-latent-space-generative-world-models-https-arxiv-dot-org-abs-2409-dot-16663>(24.09.25) Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models <a href=https://arxiv.org/abs/2409.16663>https://arxiv.org/abs/2409.16663</a></h4><ul><li>Nvidia团队</li><li>在Sensor Encoder+Action Encoder后面，接了一个Latent State Estimation采样去预测场景变化。这部分场景采样直接参与训练。
其中Action也从Policy或者模仿数据中随机选择来采样。</li></ul><figure><img src=../../ox-hugo/2025-05-08_15-02-55_screenshot_hu_79c847204acc0f63.webp height=678 width=1280></figure><figure><img src=../../ox-hugo/2025-05-08_15-08-48_screenshot_hu_cd998b2bb917fbfb.webp height=700 width=1280></figure><h4 id=25-dot-04-dot-27--learning-to-drive-from-a-world-model-https-arxiv-dot-org-abs-2504-dot-19077>(25.04.27) Learning to Drive from a World Model <a href=https://arxiv.org/abs/2504.19077>https://arxiv.org/abs/2504.19077</a></h4><ul><li>comma ai</li><li>更加像是一个模拟器视角</li><li>直接在Action上加噪音</li><li>有趣的结果是，对比了两种模拟器，一种是视频生成，一种是reprojective distortion。结果第一种表现只是略好。</li></ul><table><thead><tr><th></th><th>Reprojective</th><th>World Model</th></tr></thead><tbody><tr><td>Number of trips</td><td>47,047</td><td>40,026</td></tr><tr><td>Engaged % (time)</td><td>27.63%</td><td>29.92%</td></tr><tr><td>Engaged % (distance)</td><td>48.10%</td><td>52.49%</td></tr></tbody></table><figure><img src=../../ox-hugo/2025-05-08_15-09-58_screenshot_hu_904d4c4b46008de6.webp height=856 width=1280></figure><figure><img src=../../ox-hugo/2025-05-08_15-12-29_screenshot_hu_6ae2992e044da9ca.webp height=1155 width=1280></figure><h2 id=结尾>结尾</h2><p>暂时没想到，先写到这吧。</p></div></article></main><script src=https://utteranc.es/client.js repo=dvorak0/site issue-term=pathname theme=github-light crossorigin=anonymous async></script><script async src=https://www.yangzhenfei.com/js/mathjax-config.js></script><script type=text/javascript async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-chtml.min.js></script><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=../../posts/20250508121432-%E6%A8%A1%E4%BB%BF%E5%8F%AF%E4%BB%A5%E4%BA%A7%E7%94%9F%E6%99%BA%E8%83%BD%E5%90%97/>E2E Self-Driving: 模仿可以产生智能吗？</a></li><li><a href=../../posts/20250506141744-%E6%9D%8E%E5%85%89%E8%80%80%E8%A7%82%E5%A4%A9%E4%B8%8B/>《李光耀观天下》</a></li><li><a href=../../posts/20250506140144-%E8%A7%A3%E6%9E%84%E7%8E%B0%E4%BB%A3%E5%8C%96_%E6%B8%A9%E9%93%81%E5%86%9B%E6%BC%94%E8%AE%B2%E5%BD%95/>《解构现代化：温铁军演讲录》</a></li><li><a href=../../posts/20250207171318-%E5%A4%96%E6%98%9F%E4%BA%BA/>外星人</a></li><li><a href=../../posts/20250102143600-%E7%BB%83%E4%B9%A0%E6%97%B6%E9%95%BF%E4%B8%80%E5%B9%B4%E5%8D%8A%E7%9A%84kickstartercreator/>练习时长一年半的Kickstarter Creator</a></li></ul></div></div></aside><footer><p>&copy; 2025 <a href=https://www.yangzhenfei.com/><b>Seeking Complexity</b></a>.
<a href=https://github.com/dvorak0><b>Github</b></a>.
<a href=https://twitter.com/dvorak0><b>Twitter</b></a>.</p></footer></body></html>