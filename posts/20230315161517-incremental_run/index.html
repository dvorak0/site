<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>Universal Caching, lessons learned from NX</title><link rel=stylesheet href=../../css/style.css></head><body><header><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?41e2e31fcfdb815d942715d44866f9fc",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script>========================<br>== <a href=https://www.yangzhenfei.com>Seeking Complexity</a> ==<br>========================<div style=float:right></div><br><p><nav><a href=../../><b>Start</b></a>.
<a href=../../posts/><b>Posts</b></a>.
<a href=../../about/><b>About</b></a>.</nav></p><script src=https://www.yangzhenfei.com/js/mathjax-config.js></script>
<script type=text/javascript async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-chtml.min.js></script></header><main><article><h1>Universal Caching, lessons learned from NX</h1><b><time>2023-03-15 16:15:00</time></b>
<a href=../../tags/dm>DM</a>
<a href=../../tags/public>PUBLIC</a><div><h2 id=tl-dr>TL;DR</h2><p>purity + cache = efficient (thus practical) FP</p><h2 id=chatgpt的一个小趣事>ChatGPT的一个小趣事</h2><p><a href=../../posts/20220224200513-sicp/>SICP</a>之后，不断的又看到一些FP思想在实际工作中的使用。</p><p>近来ChatGPT大火，其中transformer结构中的self-attention有明显的recursive结构。</p><p>如何高效地推理？</p><p>我的第一反应是，给每个token维护一个 <code>dp[][]</code> ，然后去做状态转移。。。</p><p>这样的问题是把这个细节暴露地太多在 <code>GPT()</code> 外面。</p><p>参考<a href=https://kipp.ly/blog/transformer-inference-arithmetic/>Transformer Inference Arithmetic</a>，实际使用的实现是为QKV准备一个KV cache。</p><p>自然结果是等价的，只是写法不同。但是在我看来，这两种写法再次区分了两种范式：<a href=../../posts/20211202120838-declarative_programming/>declarative_programming</a>。</p><h2 id=incremental-build-test-dot-and-run>incremental build/test. and run?</h2><p>增量编译几乎是所有build工具的标配。包括test结果，常见被cache起来。</p><p>但是很少见run也被增量起来（如果是我孤陋寡闻了，请纠正我）。</p><p>是没有用吗？我觉的不是的。工程中常见地用DAG结构去组织不同计算节点。
如果头部的节点变化（不管是binary还是输入）自然需要几乎重跑整个computation graph。</p><p>但是如果只是修改尾部节点呢：</p><ol><li><p>可以手动指定，从某个节点开始，输入改成之前某次完整graph的结果。
相当于重新为这个节点准备一个graph。</p></li><li><p>允许incremental run！</p><p>这里propose一种实现incremental run的方案。</p></li></ol><h2 id=nx做了什么>NX做了什么</h2><figure><img src=../../ox-hugo/2023-03-16_11-31-23_screenshot_hu468e2a055eb2c33b2cb0e63207f04131_41968_960x715_resize_q75_h2_box_3.webp></figure><p><a href=https://nx.dev/>NX</a>提供了一种wrapper，为command或者script，提供KV cache，以支持incremental run。</p><p>key如何计算？</p><p>NX认为key可以被总结为：</p><blockquote><p>By default, the computation hash for - say - nx test remixapp includes:</p><ol><li>All the source files of remixapp and its dependencies</li><li>Relevant global configuration</li><li>Versions of external dependencies</li><li>Runtime values provisioned by the user such as the version of Node</li><li>CLI Command flags</li></ol></blockquote><p>value如何计算：console print + directories</p><h2 id=看看code>看看code</h2><p>始终觉得需要看看代码才直接地理解要怎么做。</p><ol><li><p>wrap command</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;targets&#34;</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;bazel&#34;</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;executor&#34;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;nx:run-commands&#34;</span>,
</span></span><span style=display:flex><span>             <span style=color:#e6db74>&#34;command&#34;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;bazel&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></li><li><p>run</p><p>下面 <code>nx bazel tools</code> 就是新的 <code>bazel</code> 。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>nx bazel tools build //map/processor/output:mcap_convertor_main
</span></span></code></pre></div><p>结果是：</p><figure><img src=../../ox-hugo/2023-03-16_14-10-49_screenshot_hu8e0cca835e73c41524c40d10b5aa3a93_30271_1616x288_resize_q75_h2_box_3.webp></figure><p>注意到nx这里已经在使用缓存的数据了，不过这里只是指console output。</p></li><li><p>处理输入输出</p><p>首先给我们关心的目录起名字：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;namedInputs&#34;</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;nas&#34;</span><span style=color:#f92672>:</span> [ <span style=color:#e6db74>&#34;{projectRoot}/**/*&#34;</span> ],
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;production&#34;</span><span style=color:#f92672>:</span> [ <span style=color:#e6db74>&#34;/mnt&#34;</span> ]
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;targets&#34;</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;bazel&#34;</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;executor&#34;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;nx:run-commands&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;command&#34;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;bazel&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;inputs&#34;</span><span style=color:#f92672>:</span> [<span style=color:#e6db74>&#34;default&#34;</span>, <span style=color:#e6db74>&#34;production&#34;</span>],
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;outputs&#34;</span><span style=color:#f92672>:</span> [ <span style=color:#e6db74>&#34;/tmp/bazel&#34;</span> ]
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>这样，bazel的结果，在input目录修改的时候，就会被invalidate。</p><p>如果没有的话，nx会用命中的cache结果，替换 <code>/tmp/bazel</code> 目录。</p></li><li><p>输入应该by-content</p><p>如果注意到的话，上面的输入目录的hash计算，是基于目录的。</p><p>实际使用中，我们希望是基于内容的。比如同样的内容，换了目录，依旧希望可以从cache中拿出结果。</p><p>这个可以使用S3中的<a href=https://docs.aws.amazon.com/AmazonS3/latest/API/API_Object.html>ETag</a>，ETag只与文件内容有关，与attributes（例如创建时间）无关。
把ETag的结果，放到一个额外的flag或者env里面都可以。</p><p>事实上，既然利用了s3的immutability，是不是从cache里拿出来文件也应该更快？这个我还不清楚。</p></li><li><p>share your cache</p><p><a href=https://nx.app/>nx cloud</a></p></li></ol></div></article></main><script src=https://utteranc.es/client.js repo=dvorak0/site issue-term=pathname theme=github-light crossorigin=anonymous async></script><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=../../posts/20230510165215-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86geohot/>重新认识geohot</a></li><li><a href=../../posts/20230417104236-intelligential_honest/>intelligential honest</a></li><li><a href=../../posts/20230315161517-incremental_run/>Universal Caching, lessons learned from NX</a></li><li><a href=../../posts/20230109104349-make_the_world_a_better_place/>make the world a better place</a></li><li><a href=../../posts/20221205145412-low_information_heuristics/>low_information_heuristics</a></li></ul></div></div></aside><footer><p>&copy; 2023 <a href=https://www.yangzhenfei.com><b>Seeking Complexity</b></a>.</p></footer></body></html>