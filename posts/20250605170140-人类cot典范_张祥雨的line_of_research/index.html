<!doctype html><html lang=zh-cn><head><meta charset=UTF-8><meta name=description content="self-reflections of Zhenfei Yang"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>人类CoT典范，张祥雨的Line of Research</title><link rel=stylesheet href=../../css/style.css></head><body><header><script defer src=https://worker.yangzhenfei.com/a.js></script><script defer>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JHXS14NDHV")</script><script defer src=https://cloud.umami.is/script.js data-website-id=045b5d99-a38d-410c-984f-5ac9e7cc7b76></script>========================<br>== <a href=https://www.yangzhenfei.com/>Seeking Complexity</a> ==<br>========================<div style=float:right></div><br><p><nav><a href=../../><b>Start</b></a>.
<a href=../../posts/><b>Posts</b></a>.
<a href=../../tags/><b>Tags</b></a>.
<a href=../../about/><b>About</b></a>.</nav></p></header><main><article><h1>人类CoT典范，张祥雨的Line of Research</h1><b><time>2025-06-05 17:01:00</time></b>
<a href=../../tags/public>PUBLIC</a><div><p>这个访谈似乎在张小珺自己的一系列访谈里，显得比较突出。</p><p>我自己是在听到一半的时候，决定要记录一下。</p><p>主要是被张祥雨清晰的表达震撼，明显感觉他的表达的context很长，能维持一个很长的逻辑链，有的逻辑分支走完了还能回溯。</p><p>说回内容。</p><p>可以概括为，一个发自内心对智能有追求的人，是如何对AI发展中的节点进行审美的。</p><ol><li>研究线的主旋律是如何Scale</li><li>首先Data scale，imagenet终结了数据问题，之后的很长一段时间不需要考虑Data的规模问题。所以主要考虑模型架构。</li><li>针对模型宽度的scale 做了MSRA init。（其实没懂这个逻辑）</li><li>针对模型深度的scale做了resnet，模型从几M，做到几十M。</li><li>继续加深有没有用呢，对于大模型没有用了，只要大体设计对了，性能差别不大。</li><li>在旷视做落地部署，小模型有商业价值。并且发现架构设计对小模型更有用，所以做NAS。</li><li>发现GPT3太牛了，觉得自己搞了这么多年，只不过是在做representation，NLP都做到推理能力了。离“智能”更近。</li><li>为什么NLP有scale，CV没有scale。</li><li>语言的学习形式更好，用完形填空的方法，是在学习联合概率。CV的label是在学习条件概率。</li><li>联合概率不需要label，数据更多。</li><li>CV能学习联合概率吗，换句话说，CV可以做生成任务吗？</li><li>生成任务怎么做，一个小高潮是Masked Image Modeling。但是感觉还是不对劲，毕竟依旧是人类知识的注入。<ol><li>张祥雨认为是在学习遮挡不变性而已：Understanding Masked Image Modeling via Learning Occlusion Invariant Feature</li></ol></li><li>还是要找到做图片生成的方法。</li><li>时间线拉回一点，ViT出现了，图片可以进Transformer了，把Image Token和Language Token简单对齐一下就可以做多模态了。</li><li>创业做公司，Step-1做出来了，图文混排进Transformer，decoder同时做图生成和文生成。图生成这一阶段是外挂diffusion。</li><li>结果，理解力很强，比如描述图片的能力。OCR顺手就被模型解决了。</li><li>但是生成很差，基本不可控。</li><li>更可怕的是，出发点是用图片生成这个形式（学习联合概率）来学习智能，但是发现把diffusion分支去掉，理解能力依旧很强。这不是说明图片生成并没有帮助来学习智能吗。</li><li>猜想1，数据不好，互联网上的图文对不够高质量。那么交替的做，先做一个模型，这个模型理解力很强，那么用这个模型做caption合成数据，再训练下一轮模型。</li><li>没有成功。</li><li>猜想2，模型不够大，没训好。做了一个200B激活的网络。</li><li>有了一个核心观察。模型越大，文科能力越强，理科能力越差。</li><li>怎么解释。矛头直指Next Token Prediction这个范式，或者说压缩产生智能这个范式。</li><li>举个例子：如果语料中，有两类数学题，一类是跳步的，一类是不跳步的。模型在NTP这个范式下，应该学到什么：一半概率猜测/记忆，一半概率推理。</li><li>所以就能解释了，小模型记忆能力不行，所以只有靠推理，但是大模型记忆能力好，反而有了更高的压缩率，但是现在高压缩率是有害的。</li><li>（插一句，我觉得也经常发现，记忆力好的人和推理能力好的人是两类人，这两个能力似乎就是互相排斥的）</li><li>NTP的问题能解决吗。</li><li>线索回到NLP模型，o1带来了什么启示。</li><li>CoT是有用的，从复杂度的视角，不能预期任何难度的问题都在一个Token下解决。</li><li>所以o1用CoT扩展了复杂度，从而应对不同难度的问题。</li><li>具体的方法就是rule-based RL，直接在编程和数学的领域设置reward，RL跑起来，性能提升了。</li><li>这么简单的想法，之前怎么没做成。</li><li>可能是OpenAI发现了rule-based RL应该用什么pattern的CoT，更像是在解决CoT的CoT，meta CoT问题。</li><li>他是怎么找到recheck/wait/alternatively这些关键词的。</li><li>猜测是观察数据，StackOverFlow很多回答，带有这些关键词。</li><li>总之，用独特的pattern去诱导CoT，做work了。</li><li>是RL的胜利吗。
感觉此RL已经不是彼RL了。经典的RL要解决的问题，主要是reward稀疏的问题，比如随机打游戏，通关的概率在冷启动的时候是很小的。
但是在NLP这个问题里面，pretrain的模型的搜索空间不是冷启动的。关键的critical decision只有那么几个。任何算法都可以work，不重要。</li><li>CoT的pattern算不算人类知识的注入呢，如果完全靠学习能不能学到。现在来看，base model增强之后，也是可以学到的，但是效率不高。</li><li>现在可以继续回到图片了，图片的CoT有吗。现在来看，还没有。但是已经能感觉到图片推理是核心问题了，比如看图走迷宫这种。也呼应了最近的图片推理方法的热点。</li><li>一些尝试，合成数据，自己做图片走迷宫数据。结果来看，泛化性不行。</li><li>OpenAI又来指路了，新模型o4的图片推理能力展示出来很好的泛化性。他找到的pattern是crop/resize。可能是新的答案吧。</li><li>图片的o1时刻可能会在一年内到来。</li><li>一些问题：Long Context重要吗。不重要。<ol><li>一个想法是，人类没有那么长的短期记忆。</li><li>另外，Long Context可以用很多方法去实现，比如用Function Calling，比如用两个LLM，一个做plan，一个做execution，执行的LLM可以并行多实例。
对于一个给定的逻辑树，遍历所需要的context就从N，变成Log(N)。</li><li>两个LLM的是agent系统，不是端到端模型。这种说法对吗，当然不对，有了RL，可以把multi-LLM一起训练，也用rule-based reward，强迫模型自己找到合作方式，在有限的context length下。</li></ol></li><li>AGI的关键方法都找到了吗？感觉下一层还需要解决一个模型自驱动的问题，毕竟人类不是做每件事情都有KPI的。</li></ol></div></article></main><script src=https://utteranc.es/client.js repo=dvorak0/site issue-term=pathname theme=github-light crossorigin=anonymous async></script><script async src=https://www.yangzhenfei.com/js/mathjax-config.js></script><script type=text/javascript async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-chtml.min.js></script><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=../../posts/20251027161231-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86chris_lattner/>重新认识Chris Lattner</a></li><li><a href=../../posts/20250903175454-%E9%B1%BC%E5%92%8C%E7%86%8A%E6%8E%8C%E6%88%91%E8%A6%81%E5%85%BC%E5%BE%97_ros2%E9%80%82%E5%90%88%E9%87%8F%E4%BA%A7%E5%90%97/>鱼和熊掌我要兼得：ROS2适合量产吗</a></li><li><a href=../../posts/20250718102851-oop_considered_harmful/>OOP considered harmful</a></li><li><a href=../../posts/20250605170140-%E4%BA%BA%E7%B1%BBcot%E5%85%B8%E8%8C%83_%E5%BC%A0%E7%A5%A5%E9%9B%A8%E7%9A%84line_of_research/>人类CoT典范，张祥雨的Line of Research</a></li><li><a href=../../posts/20250516101712-building_music_theory_from_the_scratch/>Music Theory: Building from the Scratch</a></li></ul></div></div></aside><footer><p>&copy; 2025 <a href=https://www.yangzhenfei.com/><b>Seeking Complexity</b></a>.
<a href=https://github.com/dvorak0><b>Github</b></a>.
<a href=https://twitter.com/dvorak0><b>Twitter</b></a>.</p></footer></body></html>