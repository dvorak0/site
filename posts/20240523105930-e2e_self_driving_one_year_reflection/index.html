<!doctype html><html lang=zh-cn><head><meta charset=UTF-8><meta name=description content="self-reflections of Zhenfei Yang"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>E2E Self-Driving One-year Reflection</title><link rel=stylesheet href=../../css/style.css></head><body><header><script defer src=https://worker.yangzhenfei.com/a.js></script><script defer>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JHXS14NDHV")</script><script defer src=https://cloud.umami.is/script.js data-website-id=045b5d99-a38d-410c-984f-5ac9e7cc7b76></script>========================<br>== <a href=https://www.yangzhenfei.com/>Seeking Complexity</a> ==<br>========================<div style=float:right></div><br><p><nav><a href=../../><b>Start</b></a>.
<a href=../../posts/><b>Posts</b></a>.
<a href=../../tags/><b>Tags</b></a>.
<a href=../../about/><b>About</b></a>.</nav></p></header><main><article><h1>E2E Self-Driving One-year Reflection</h1><b><time>2024-05-23 10:59:00</time></b>
<a href=../../tags/e2e>e2e</a>
<a href=../../tags/public>PUBLIC</a>
<a href=../../tags/dm>DM</a><div><p>(shamefully)因为wayve的新融资，不免的再次想起这个话题。</p><p>翻出来<a href=../../posts/20230322100018-end_to_end_selfdriving_in_the_era_of_gpt/>E2E Self-Driving in the Era of GPT</a>来看，大部分想法是一致的，现在想到的和当时想到的并没有明显矛盾的地方。</p><p>不过有一些进一步的想法。</p><p>先回忆起试验结果<a href>comma_ai</a>，当前明显的结果是，当前模型的输出是不够好的，主要有两个证据：</p><ol><li>carla的结果保持了一个很低的分数，上次自己实验用comma.ai的model在模拟器表现的结果是安全有余，经常卡住</li><li>还是要承认，结合其他车企的表现，目前接管率还是不够低，但是这个gap在变得更小。<ul><li>参考<a href=../../posts/20240130180127-%E5%85%A8%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E7%9A%84%E9%87%8C%E7%A8%8B%E7%A2%91_%E5%90%97/>全自动驾驶的里程碑，吗？</a></li><li>再结合百度在无人的无人驾驶部署，打听目前是1安全员对2台车。不知道是不是真的百度内部得到了一个模型，有机会做到盈利？
不过再结合小道消息，也感觉百度的大公司病太严重了，体现在员工的养老状态，加上leader们对于向上汇报的过度重视。</li></ul></li></ol><p>所以在今天，</p><h2 id=新的熵增是什么>新的熵增是什么</h2><h3 id=larger-model>larger model</h3><p>今天看起来很明显，但是去年这个时候竟然完全没有提，甚至没有去看comma ai的model size。</p><p>今天查了下发现，模型是49.1M。这个size如果不是隐瞒了严重的问题的话，就一定是一个大的潜在机会。</p><h3 id=视频生成的进展>视频生成的进展</h3><p>这里要提到，自上次的乐观之后，新了解到的一个概念，事关模仿学习的根基。</p><p>这个问题有点难以刻画，好像也没有形成普遍的概念。</p><p>这个问题是在描述，如果这个模型模仿的数据都是高水平数据（人类水平），它是否能学会应对事故（因为救车操作，或者说避免车道画龙操作，在数据里很少）。</p><p>更正式一点说，有点像模仿学习的数据分布，要比部署时候在control loop里面看到的数据分布，更加“窄”。</p><p>我自己意识到这个问题是在<a href=https://geohot.github.io/blog/jekyll/update/2023/11/18/imitation-learning.html>Imitation Learning</a>。幸运的是，geohot同时给出了一个提示。</p><p>虽然他没有说清楚是什么解法，我结合当时的时间以及<a href=https://github.com/commaai/commavq>https://github.com/commaai/commavq</a>。</p><p>我现在认为这个解法，是用视频生成去做augmentation！用conditioned video generation去仿真。
比如把一个车道线居中操作，仿真成画龙（再控制回居中）。这样让模型去扩大适应的分布。</p><h3 id=更普遍地看中数据质量>更普遍地看中数据质量。</h3><p>更加相信：数据集的high-quality是很重要的，比quantity要更加重要。</p><p>手工做去数据的去重，权重调整，是现在LLM训练的标配。</p><h2 id=新的问题是什么>新的问题是什么</h2><p>结合以上两点吧。有没有机会做到：</p><ul><li>carla的碰撞率降低一个数量级到1%，用各种方法。</li><li>如果可以，那么model size和collision rate的plot，是不是具备scaling law？</li><li>如何“精心地”准备数据。现在的两个做法：<ol><li>用youtube driving。行车记录仪类型的。这里需要跑定位，然后用视频+轨迹做监督。</li><li>自己录。自动驾驶类的，这里不跑定位，用视频+控制信号做监督。</li></ol></li></ul></div></article></main><script src=https://utteranc.es/client.js repo=dvorak0/site issue-term=pathname theme=github-light crossorigin=anonymous async></script><script async src=https://www.yangzhenfei.com/js/mathjax-config.js></script><script type=text/javascript async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-chtml.min.js></script><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=../../posts/20250605170140-%E4%BA%BA%E7%B1%BBcot%E5%85%B8%E8%8C%83_%E5%BC%A0%E7%A5%A5%E9%9B%A8%E7%9A%84line_of_research/>人类CoT典范，张祥雨的Line of Research</a></li><li><a href=../../posts/20250516101712-building_music_theory_from_the_scratch/>Music Theory: Building from the Scratch</a></li><li><a href=../../posts/20250508121432-%E6%A8%A1%E4%BB%BF%E5%8F%AF%E4%BB%A5%E4%BA%A7%E7%94%9F%E6%99%BA%E8%83%BD%E5%90%97/>E2E Self-Driving: 模仿可以产生智能吗？</a></li><li><a href=../../posts/20250506141744-%E6%9D%8E%E5%85%89%E8%80%80%E8%A7%82%E5%A4%A9%E4%B8%8B/>《李光耀观天下》</a></li><li><a href=../../posts/20250506140144-%E8%A7%A3%E6%9E%84%E7%8E%B0%E4%BB%A3%E5%8C%96_%E6%B8%A9%E9%93%81%E5%86%9B%E6%BC%94%E8%AE%B2%E5%BD%95/>《解构现代化：温铁军演讲录》</a></li></ul></div></div></aside><footer><p>&copy; 2025 <a href=https://www.yangzhenfei.com/><b>Seeking Complexity</b></a>.
<a href=https://github.com/dvorak0><b>Github</b></a>.
<a href=https://twitter.com/dvorak0><b>Twitter</b></a>.</p></footer></body></html>