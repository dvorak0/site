<!doctype html><html lang=zh-cn><head><meta charset=UTF-8><meta name=description content="self-reflections of Zhenfei Yang"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><style type=text/css>body{font-family:monospace}</style><title>LLM is dead, long live agent</title>
<link rel=stylesheet href=../../css/style.css></head><body><header><script defer src=https://worker.yangzhenfei.com/a.js></script><script defer>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JHXS14NDHV")</script>========================<br>== <a href=https://www.yangzhenfei.com/>Seeking Complexity</a> ==<br>========================<div style=float:right></div><br><p><nav><a href=../../><b>Start</b></a>.
<a href=../../posts/><b>Posts</b></a>.
<a href=../../tags/><b>Tags</b></a>.
<a href=../../about/><b>About</b></a>.</nav></p></header><main><article><h1>LLM is dead, long live agent</h1><b><time>2023-11-08 16:20:00</time></b>
<a href=../../tags/public>PUBLIC</a><div><figure><img src=../../ox-hugo/2023-11-08_16-22-44_screenshot_hu_d33cfe398fb9ca8b.webp height=847 width=1280></figure><p>是这样吗？</p><p>自Tesla之后，又多了一个需要逐帧学习的发布会。</p><p>那么OpenAI在说什么。</p><p>确实需要把重点从world model移开，关注如何更好地使用这个先验模型。</p><p>就好像即使人出生的时候已经如此聪明了，还是要经历长时间地教育去获得更多慢思考的品质：耐心、共情、自省等等。</p><p>LLM给我们的，只有next ONE token generation接口，那么只是朴素地使用这个接口，能写出来最好的东西吗，现在看起来是未必的。</p><p>举一个最简单的例子：RAG(Retrieval Augmented Generation)是不是一个solved problem？不是，否则就不会有那么多的RAG方法。</p><figure><img src=../../ox-hugo/2023-11-08_16-34-10_screenshot_hu_8364998ed99a91d6.webp height=507 width=1280></figure><p>再结合yann lecun的挑战，我们确实能在这个空间里找到那个token sequences吗，尤其是在面对复杂任务的时候。</p><figure><img src=../../ox-hugo/2023-11-09_13-48-30_screenshot_hu_f29564a55389d64e.webp height=711 width=1280></figure><p>新的机会，但是也需要一些新的突破？</p></div></article></main><script src=https://utteranc.es/client.js repo=dvorak0/site issue-term=pathname theme=github-light crossorigin=anonymous async></script><script async src=https://www.yangzhenfei.com/js/mathjax-config.js></script><script type=text/javascript async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-chtml.min.js></script><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=../../posts/20250508121432-%E6%A8%A1%E4%BB%BF%E5%8F%AF%E4%BB%A5%E4%BA%A7%E7%94%9F%E6%99%BA%E8%83%BD%E5%90%97/>E2E Self-Driving: 模仿可以产生智能吗？</a></li><li><a href=../../posts/20250506141744-%E6%9D%8E%E5%85%89%E8%80%80%E8%A7%82%E5%A4%A9%E4%B8%8B/>《李光耀观天下》</a></li><li><a href=../../posts/20250506140144-%E8%A7%A3%E6%9E%84%E7%8E%B0%E4%BB%A3%E5%8C%96_%E6%B8%A9%E9%93%81%E5%86%9B%E6%BC%94%E8%AE%B2%E5%BD%95/>《解构现代化：温铁军演讲录》</a></li><li><a href=../../posts/20250207171318-%E5%A4%96%E6%98%9F%E4%BA%BA/>外星人</a></li><li><a href=../../posts/20250102143600-%E7%BB%83%E4%B9%A0%E6%97%B6%E9%95%BF%E4%B8%80%E5%B9%B4%E5%8D%8A%E7%9A%84kickstartercreator/>练习时长一年半的Kickstarter Creator</a></li></ul></div></div></aside><footer><p>&copy; 2025 <a href=https://www.yangzhenfei.com/><b>Seeking Complexity</b></a>.
<a href=https://github.com/dvorak0><b>Github</b></a>.
<a href=https://twitter.com/dvorak0><b>Twitter</b></a>.</p></footer></body></html>